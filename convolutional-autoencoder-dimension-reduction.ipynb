{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016119,
     "end_time": "2022-11-03T09:00:07.285869",
     "exception": false,
     "start_time": "2022-11-03T09:00:07.26975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1  style='color:white; background:#0096FF ; border:0;text-align: center' class=\"list-group-item list-group-item-action active\">Stacked & Convolutional Autoencoder for Dimensionality Reduction.</h1><a id = \"1\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01408,
     "end_time": "2022-11-03T09:00:07.314816",
     "exception": false,
     "start_time": "2022-11-03T09:00:07.300736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:#0096FF ; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation</center></h3>\n",
    "\n",
    "* [Importing Libraries](#1.1)\n",
    "    \n",
    "* [Data Preprocessing](#2)\n",
    "    \n",
    "    - [Load Training Dataset](#2.1)\n",
    "    \n",
    "    - [Split Data](#2.2)\n",
    "    \n",
    "    - [Image Preprocessing](#2.3)\n",
    "    \n",
    "    \n",
    "* [Data Visualization](#3)\n",
    "\n",
    "    * [Model Summary](#5)\n",
    "    \n",
    "    \n",
    "* [**Autoencoder Architecture**](#5.3)\n",
    "    \n",
    "   - [**Stacked Autoencoder**](#5.3)\n",
    "    \n",
    "   - [**Convolutional autoencoder**](#5.5)\n",
    "    \n",
    "* [Save Model](#6.2)\n",
    "\n",
    "* [Plot Evaluation](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014125,
     "end_time": "2022-11-03T09:00:07.343442",
     "exception": false,
     "start_time": "2022-11-03T09:00:07.329317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Objective**\n",
    "* The stacker Autoencoder is used to Dimensionality reduction of the given Digit images from the MNIST dataset and Fashion MNIST dataset implemented using Tensorflow 2.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014533,
     "end_time": "2022-11-03T09:00:07.373353",
     "exception": false,
     "start_time": "2022-11-03T09:00:07.35882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1  style='color:white; background:#0096FF ; border:0;text-align: center' class=\"list-group-item list-group-item-action active\">1. IMPORTING LIBRARIES</h1><a id = \"1.1\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:19.920427Z",
     "iopub.status.busy": "2022-11-14T08:03:19.919894Z",
     "iopub.status.idle": "2022-11-14T08:03:26.026897Z",
     "shell.execute_reply": "2022-11-14T08:03:26.025931Z",
     "shell.execute_reply.started": "2022-11-14T08:03:19.920313Z"
    },
    "papermill": {
     "duration": 6.684705,
     "end_time": "2022-11-03T09:00:14.073092",
     "exception": false,
     "start_time": "2022-11-03T09:00:07.388387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import decomposition\n",
    "\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, Activation,Flatten, Conv2D, Dropout,Reshape\n",
    "from tensorflow.keras.layers import MaxPool2D, LSTM, BatchNormalization,concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.layers import ELU\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:26.029648Z",
     "iopub.status.busy": "2022-11-14T08:03:26.028991Z",
     "iopub.status.idle": "2022-11-14T08:03:26.046799Z",
     "shell.execute_reply": "2022-11-14T08:03:26.04592Z",
     "shell.execute_reply.started": "2022-11-14T08:03:26.029611Z"
    },
    "papermill": {
     "duration": 0.028704,
     "end_time": "2022-11-03T09:00:14.117918",
     "exception": false,
     "start_time": "2022-11-03T09:00:14.089214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014832,
     "end_time": "2022-11-03T09:00:14.14848",
     "exception": false,
     "start_time": "2022-11-03T09:00:14.133648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style='color:white; background:#0096FF ; border:0;text-align: center' class=\"list-group-item list-group-item-action active\">2. DATA PREPROCESSING</h1><a id = \"2\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015145,
     "end_time": "2022-11-03T09:00:14.179322",
     "exception": false,
     "start_time": "2022-11-03T09:00:14.164177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1  style='color:#0096FF; background:white ; border:0' class=\"list-group-item list-group-item-action active\">2.1 LOAD TRAINING DATASET</h1><a id = \"2.1\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:26.049105Z",
     "iopub.status.busy": "2022-11-14T08:03:26.048749Z",
     "iopub.status.idle": "2022-11-14T08:03:33.560944Z",
     "shell.execute_reply": "2022-11-14T08:03:33.559937Z",
     "shell.execute_reply.started": "2022-11-14T08:03:26.049071Z"
    },
    "papermill": {
     "duration": 3.433323,
     "end_time": "2022-11-03T09:00:17.627898",
     "exception": false,
     "start_time": "2022-11-03T09:00:14.194575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fashion_train_data = pd.read_csv('./Datasets/fashion-mnist_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:33.56397Z",
     "iopub.status.busy": "2022-11-14T08:03:33.563424Z",
     "iopub.status.idle": "2022-11-14T08:03:36.207234Z",
     "shell.execute_reply": "2022-11-14T08:03:36.206229Z",
     "shell.execute_reply.started": "2022-11-14T08:03:33.563927Z"
    },
    "papermill": {
     "duration": 2.106856,
     "end_time": "2022-11-03T09:00:19.750953",
     "exception": false,
     "start_time": "2022-11-03T09:00:17.644097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fashion_test_data = pd.read_csv('./Datasets/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016185,
     "end_time": "2022-11-03T09:00:19.782989",
     "exception": false,
     "start_time": "2022-11-03T09:00:19.766804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3  style='color:#0096FF; background:#FFF ' class=\"list-group-item list-group-item-action active\">Data Dimension</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Dimension of the Digits MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:36.20925Z",
     "iopub.status.busy": "2022-11-14T08:03:36.208876Z",
     "iopub.status.idle": "2022-11-14T08:03:36.215727Z",
     "shell.execute_reply": "2022-11-14T08:03:36.21473Z",
     "shell.execute_reply.started": "2022-11-14T08:03:36.209216Z"
    },
    "papermill": {
     "duration": 0.025166,
     "end_time": "2022-11-03T09:00:19.823782",
     "exception": false,
     "start_time": "2022-11-03T09:00:19.798616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv size is (60000, 785)\n",
      "test.csv size is (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.csv size is {fashion_train_data.shape}\")\n",
    "print(f\"test.csv size is {fashion_test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= fashion_train_data\n",
    "test_data= fashion_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:36.218151Z",
     "iopub.status.busy": "2022-11-14T08:03:36.217485Z",
     "iopub.status.idle": "2022-11-14T08:03:36.247115Z",
     "shell.execute_reply": "2022-11-14T08:03:36.246245Z",
     "shell.execute_reply.started": "2022-11-14T08:03:36.218118Z"
    },
    "papermill": {
     "duration": 0.045823,
     "end_time": "2022-11-03T09:00:19.885436",
     "exception": false,
     "start_time": "2022-11-03T09:00:19.839613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:36.248907Z",
     "iopub.status.busy": "2022-11-14T08:03:36.248478Z",
     "iopub.status.idle": "2022-11-14T08:03:38.238024Z",
     "shell.execute_reply": "2022-11-14T08:03:38.236937Z",
     "shell.execute_reply.started": "2022-11-14T08:03:36.248869Z"
    },
    "papermill": {
     "duration": 2.412627,
     "end_time": "2022-11-03T09:00:22.314078",
     "exception": false,
     "start_time": "2022-11-03T09:00:19.901451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.101933</td>\n",
       "      <td>0.247967</td>\n",
       "      <td>0.411467</td>\n",
       "      <td>0.805767</td>\n",
       "      <td>2.198283</td>\n",
       "      <td>5.682000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.625400</td>\n",
       "      <td>23.300683</td>\n",
       "      <td>16.588267</td>\n",
       "      <td>17.869433</td>\n",
       "      <td>22.814817</td>\n",
       "      <td>17.911483</td>\n",
       "      <td>8.520633</td>\n",
       "      <td>2.753300</td>\n",
       "      <td>0.855517</td>\n",
       "      <td>0.07025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872305</td>\n",
       "      <td>0.094689</td>\n",
       "      <td>0.271011</td>\n",
       "      <td>1.222324</td>\n",
       "      <td>2.452871</td>\n",
       "      <td>4.306912</td>\n",
       "      <td>5.836188</td>\n",
       "      <td>8.215169</td>\n",
       "      <td>14.093378</td>\n",
       "      <td>23.819481</td>\n",
       "      <td>...</td>\n",
       "      <td>57.545242</td>\n",
       "      <td>48.854427</td>\n",
       "      <td>41.979611</td>\n",
       "      <td>43.966032</td>\n",
       "      <td>51.830477</td>\n",
       "      <td>45.149388</td>\n",
       "      <td>29.614859</td>\n",
       "      <td>17.397652</td>\n",
       "      <td>9.356960</td>\n",
       "      <td>2.12587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>170.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       4.500000      0.000900      0.006150      0.035333      0.101933   \n",
       "std        2.872305      0.094689      0.271011      1.222324      2.452871   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000     16.000000     36.000000    226.000000    164.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.247967      0.411467      0.805767      2.198283      5.682000   \n",
       "std        4.306912      5.836188      8.215169     14.093378     23.819481   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      227.000000    230.000000    224.000000    255.000000    254.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean   ...     34.625400     23.300683     16.588267     17.869433   \n",
       "std    ...     57.545242     48.854427     41.979611     43.966032   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...     58.000000      9.000000      0.000000      0.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      22.814817     17.911483      8.520633      2.753300      0.855517   \n",
       "std       51.830477     45.149388     29.614859     17.397652      9.356960   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  60000.00000  \n",
       "mean       0.07025  \n",
       "std        2.12587  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max      170.00000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01554,
     "end_time": "2022-11-03T09:00:22.346355",
     "exception": false,
     "start_time": "2022-11-03T09:00:22.330815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**To Check how many pixel columns are there such that all their values are zero as we can see from the describe() function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data dimension of the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:38.240203Z",
     "iopub.status.busy": "2022-11-14T08:03:38.239545Z",
     "iopub.status.idle": "2022-11-14T08:03:38.245904Z",
     "shell.execute_reply": "2022-11-14T08:03:38.24467Z",
     "shell.execute_reply.started": "2022-11-14T08:03:38.240166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv size is (60000, 785)\n",
      "test.csv size is (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.csv size is {fashion_train_data.shape}\")\n",
    "print(f\"test.csv size is {fashion_test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015204,
     "end_time": "2022-11-03T09:01:59.656003",
     "exception": false,
     "start_time": "2022-11-03T09:01:59.640799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3  style='color:#0096FF; background:#FFF ' class=\"list-group-item list-group-item-action active\">Missing values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:38.247952Z",
     "iopub.status.busy": "2022-11-14T08:03:38.247364Z",
     "iopub.status.idle": "2022-11-14T08:03:38.297976Z",
     "shell.execute_reply": "2022-11-14T08:03:38.296951Z",
     "shell.execute_reply.started": "2022-11-14T08:03:38.247918Z"
    },
    "papermill": {
     "duration": 0.071266,
     "end_time": "2022-11-03T09:01:59.743263",
     "exception": false,
     "start_time": "2022-11-03T09:01:59.671997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "           ..\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "pixel784    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:38.302379Z",
     "iopub.status.busy": "2022-11-14T08:03:38.302078Z",
     "iopub.status.idle": "2022-11-14T08:03:38.361137Z",
     "shell.execute_reply": "2022-11-14T08:03:38.360133Z",
     "shell.execute_reply.started": "2022-11-14T08:03:38.302354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "           ..\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "pixel784    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016287,
     "end_time": "2022-11-03T09:01:59.775872",
     "exception": false,
     "start_time": "2022-11-03T09:01:59.759585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* No missing values in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:38.362999Z",
     "iopub.status.busy": "2022-11-14T08:03:38.362633Z",
     "iopub.status.idle": "2022-11-14T08:03:38.368876Z",
     "shell.execute_reply": "2022-11-14T08:03:38.366615Z",
     "shell.execute_reply.started": "2022-11-14T08:03:38.362964Z"
    },
    "papermill": {
     "duration": 0.02533,
     "end_time": "2022-11-03T09:01:59.818399",
     "exception": false,
     "start_time": "2022-11-03T09:01:59.793069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels=train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01666,
     "end_time": "2022-11-03T09:01:59.851841",
     "exception": false,
     "start_time": "2022-11-03T09:01:59.835181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style='color:white; background:#0096FF ; border:0;text-align: center' class=\"list-group-item list-group-item-action active\">2.2 SPLIT DATA</h1><a id = \"2.2\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:38.371216Z",
     "iopub.status.busy": "2022-11-14T08:03:38.370534Z",
     "iopub.status.idle": "2022-11-14T08:03:38.378738Z",
     "shell.execute_reply": "2022-11-14T08:03:38.377816Z",
     "shell.execute_reply.started": "2022-11-14T08:03:38.37118Z"
    },
    "papermill": {
     "duration": 0.024587,
     "end_time": "2022-11-03T09:01:59.893265",
     "exception": false,
     "start_time": "2022-11-03T09:01:59.868678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28 # 28*28 dimension of image reshape\n",
    "num_classes = 10 # 10 number of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016153,
     "end_time": "2022-11-03T09:01:59.925574",
     "exception": false,
     "start_time": "2022-11-03T09:01:59.909421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style='color:white; background:#0096FF ; border:0;text-align: center' class=\"list-group-item list-group-item-action active\">2.3 PREPROCESSING</h1><a id = \"2.3\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016213,
     "end_time": "2022-11-03T09:01:59.958033",
     "exception": false,
     "start_time": "2022-11-03T09:01:59.94182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3  style='color:#0096FF; background:#FFF ' class=\"list-group-item list-group-item-action active\">One hot Encoding</h3>\n",
    "\n",
    "One hot encoding is one method of converting data to prepare it for an algorithm and get a better prediction. With one-hot, we convert each categorical value into a new categorical column and assign a binary value of 1 or 0 to those columns. Each integer value is represented as a binary vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:38.382561Z",
     "iopub.status.busy": "2022-11-14T08:03:38.38182Z",
     "iopub.status.idle": "2022-11-14T08:03:38.627361Z",
     "shell.execute_reply": "2022-11-14T08:03:38.626282Z",
     "shell.execute_reply.started": "2022-11-14T08:03:38.382526Z"
    },
    "papermill": {
     "duration": 0.138782,
     "end_time": "2022-11-03T09:02:00.11374",
     "exception": false,
     "start_time": "2022-11-03T09:01:59.974958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_prep(raw):\n",
    "    out_y = tensorflow.keras.utils.to_categorical(raw.label, num_classes)\n",
    "\n",
    "    num_images = raw.shape[0]\n",
    "    x_as_array = raw.values[:,1:]\n",
    "    x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n",
    "    # normalization\n",
    "    out_x = x_shaped_array / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "x, y = data_prep(train_data)\n",
    "x_fashion,y_fashion = data_prep(fashion_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016143,
     "end_time": "2022-11-03T09:02:00.147349",
     "exception": false,
     "start_time": "2022-11-03T09:02:00.131206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3  style='color:#0096FF; background:#FFF ' class=\"list-group-item list-group-item-action active\">Data Split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:38.629594Z",
     "iopub.status.busy": "2022-11-14T08:03:38.629182Z",
     "iopub.status.idle": "2022-11-14T08:03:39.078368Z",
     "shell.execute_reply": "2022-11-14T08:03:39.077189Z",
     "shell.execute_reply.started": "2022-11-14T08:03:38.629553Z"
    },
    "papermill": {
     "duration": 0.487876,
     "end_time": "2022-11-03T09:02:00.651253",
     "exception": false,
     "start_time": "2022-11-03T09:02:00.163377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)#ratio 90:10\n",
    "x_train, x_val, y_train, y_val= train_test_split(x_train, y_train, test_size = 1/9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:39.080334Z",
     "iopub.status.busy": "2022-11-14T08:03:39.079856Z",
     "iopub.status.idle": "2022-11-14T08:03:39.723319Z",
     "shell.execute_reply": "2022-11-14T08:03:39.72218Z",
     "shell.execute_reply.started": "2022-11-14T08:03:39.080288Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_fashion, x_test_fashion, y_train_fashion, y_test_fashion = train_test_split(x_fashion, y_fashion, test_size=0.1, random_state=42)#ratio 90:10\n",
    "x_train_fashion, x_val_fashion, y_train_fashion, y_val_fashion= train_test_split(x_train_fashion, y_train_fashion, test_size = 1/9, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016233,
     "end_time": "2022-11-03T09:02:00.684402",
     "exception": false,
     "start_time": "2022-11-03T09:02:00.668169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Splitting data into 90% training and 10% test data.\n",
    "* Splitting the training data into 90% training data and 10% validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015612,
     "end_time": "2022-11-03T09:02:00.716438",
     "exception": false,
     "start_time": "2022-11-03T09:02:00.700826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3  style='color:#0096FF; background:#FFF ' class=\"list-group-item list-group-item-action active\">Reshaping the Data to 4 dimension</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:39.724978Z",
     "iopub.status.busy": "2022-11-14T08:03:39.724614Z",
     "iopub.status.idle": "2022-11-14T08:03:39.807324Z",
     "shell.execute_reply": "2022-11-14T08:03:39.806266Z",
     "shell.execute_reply.started": "2022-11-14T08:03:39.724944Z"
    },
    "papermill": {
     "duration": 0.110745,
     "end_time": "2022-11-03T09:02:00.842543",
     "exception": false,
     "start_time": "2022-11-03T09:02:00.731798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 7850000 into shape (28,28,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-82f29eaeba33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# reshaping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 7850000 into shape (28,28,1)"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "test_data = test_data / 255  \n",
    "# reshaping\n",
    "test_data = test_data.values.reshape(-1,28,28,1)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:39.809299Z",
     "iopub.status.busy": "2022-11-14T08:03:39.808716Z",
     "iopub.status.idle": "2022-11-14T08:03:39.844576Z",
     "shell.execute_reply": "2022-11-14T08:03:39.843182Z",
     "shell.execute_reply.started": "2022-11-14T08:03:39.809242Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "fashion_test_data = fashion_test_data / 255  \n",
    "# reshaping\n",
    "#fashion_test_data = fashion_test_data.values.reshape(-1,28,28,1)\n",
    "#fashion_test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016686,
     "end_time": "2022-11-03T09:02:00.876143",
     "exception": false,
     "start_time": "2022-11-03T09:02:00.859457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3  style='color:#0096FF; background:#FFF ' class=\"list-group-item list-group-item-action active\">Data Dimension</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions for MNIST Digit dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:39.846905Z",
     "iopub.status.busy": "2022-11-14T08:03:39.846436Z",
     "iopub.status.idle": "2022-11-14T08:03:39.854199Z",
     "shell.execute_reply": "2022-11-14T08:03:39.853044Z",
     "shell.execute_reply.started": "2022-11-14T08:03:39.846865Z"
    },
    "papermill": {
     "duration": 0.027199,
     "end_time": "2022-11-03T09:02:00.9203",
     "exception": false,
     "start_time": "2022-11-03T09:02:00.893101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Training data size is {x_train.shape}\")\n",
    "print(f\"Training data size is {y_train.shape}\")\n",
    "print(f\"Testing data size is {x_test.shape}\")\n",
    "print(f\"Training data size is {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions of Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:39.856469Z",
     "iopub.status.busy": "2022-11-14T08:03:39.855821Z",
     "iopub.status.idle": "2022-11-14T08:03:39.863061Z",
     "shell.execute_reply": "2022-11-14T08:03:39.862139Z",
     "shell.execute_reply.started": "2022-11-14T08:03:39.856432Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Training data size is {x_train_fashion.shape}\")\n",
    "print(f\"Training data size is {y_train_fashion.shape}\")\n",
    "print(f\"Testing data size is {x_test_fashion.shape}\")\n",
    "print(f\"Training data size is {y_test_fashion.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016798,
     "end_time": "2022-11-03T09:02:00.953712",
     "exception": false,
     "start_time": "2022-11-03T09:02:00.936914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1  style='color:white; background:#0096FF ; border:0;text-align: center' class=\"list-group-item list-group-item-action active\">3. VISUALIZE DATA</h1><a id = \"3\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:39.865082Z",
     "iopub.status.busy": "2022-11-14T08:03:39.864414Z",
     "iopub.status.idle": "2022-11-14T08:03:39.873644Z",
     "shell.execute_reply": "2022-11-14T08:03:39.872843Z",
     "shell.execute_reply.started": "2022-11-14T08:03:39.865048Z"
    },
    "papermill": {
     "duration": 0.029003,
     "end_time": "2022-11-03T09:02:00.999563",
     "exception": false,
     "start_time": "2022-11-03T09:02:00.97056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "title=[j for i in range(1, 10) for j in range(0,10) if y_train[i][j] == 1]\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:39.875516Z",
     "iopub.status.busy": "2022-11-14T08:03:39.874943Z",
     "iopub.status.idle": "2022-11-14T08:03:39.884556Z",
     "shell.execute_reply": "2022-11-14T08:03:39.883733Z",
     "shell.execute_reply.started": "2022-11-14T08:03:39.875481Z"
    }
   },
   "outputs": [],
   "source": [
    "title_fashion=[j for i in range(1, 10) for j in range(0,10) if y_train_fashion[i][j] == 1]\n",
    "title_fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the Fashion MNIST dataset.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:39.886464Z",
     "iopub.status.busy": "2022-11-14T08:03:39.885788Z",
     "iopub.status.idle": "2022-11-14T08:03:40.944483Z",
     "shell.execute_reply": "2022-11-14T08:03:40.943299Z",
     "shell.execute_reply.started": "2022-11-14T08:03:39.886342Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "for i in range(1, 10):\n",
    "    plt.subplot(330 + i)\n",
    "    plt.imshow(x_train_fashion[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(title_fashion[i-1])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the Digits MNIST dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:40.947098Z",
     "iopub.status.busy": "2022-11-14T08:03:40.946426Z",
     "iopub.status.idle": "2022-11-14T08:03:42.11924Z",
     "shell.execute_reply": "2022-11-14T08:03:42.118218Z",
     "shell.execute_reply.started": "2022-11-14T08:03:40.947053Z"
    },
    "papermill": {
     "duration": 1.195223,
     "end_time": "2022-11-03T09:02:02.57003",
     "exception": false,
     "start_time": "2022-11-03T09:02:01.374807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,9))\n",
    "for i in range(1, 10):\n",
    "    plt.subplot(330 + i)\n",
    "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(title[i-1])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047001,
     "end_time": "2022-11-03T09:02:06.397265",
     "exception": false,
     "start_time": "2022-11-03T09:02:06.350264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1  style='color:white; background:#0096FF ; border:0;text-align: center' class=\"list-group-item list-group-item-action active\">4. MODEL SUMMARY</h1><a id = \"5\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019253,
     "end_time": "2022-11-03T09:02:12.231133",
     "exception": false,
     "start_time": "2022-11-03T09:02:12.21188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1  style='color:#0096FF; background:#FFF ' class=\"list-group-item list-group-item-action active\">Stacked Autoencoder Architecture</h1><a id = \"5.3\" ></a>\n",
    "\n",
    "  **Stacked Autoencoder** is a method used for compressing and dimensionality reduction of the Digit images.\n",
    "* Stacked Autoencoder has stacked_encoder and stacker decoder layers.  \n",
    "\n",
    "**Stacked Encoder**\n",
    "\n",
    "* The Stacked encoder has 3 hidden layers. Flatten layer with 100 neural units, Dense layer with 100 neurons , Dense layer with 20 neurons with 'SELU' activation functions.\n",
    "\n",
    "**Stacked Decoder**\n",
    "\n",
    "* The Stacked encoder has 3 hidden layers. Dense layer with 100 neural units, Dense layer with 784 neurons (activation='sigmoid') , Reshape layer with 28,28 image rows,image columns.\n",
    "\n",
    "The Autoencoder model is one of the Dimensionality reduction technique and denoises the outliers, errors in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:42.121443Z",
     "iopub.status.busy": "2022-11-14T08:03:42.120525Z",
     "iopub.status.idle": "2022-11-14T08:03:45.239022Z",
     "shell.execute_reply": "2022-11-14T08:03:45.237108Z",
     "shell.execute_reply.started": "2022-11-14T08:03:42.121405Z"
    },
    "papermill": {
     "duration": 0.419767,
     "end_time": "2022-11-03T09:02:12.670278",
     "exception": false,
     "start_time": "2022-11-03T09:02:12.250511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked_encoder = Sequential()\n",
    "\n",
    "stacked_encoder.add(Flatten(input_shape=(img_rows, img_cols, 1)))\n",
    "stacked_encoder.add(Dense(100,activation='selu'))\n",
    "stacked_encoder.add(Dense(30,activation='selu'))\n",
    "\n",
    "stacked_decoder=Sequential()\n",
    "stacked_decoder.add(Dense(100 ,activation='selu',input_shape=[30]))\n",
    "stacked_decoder.add(Dense(28*28 ,activation='sigmoid'))\n",
    "stacked_decoder.add(Reshape([28,28]))\n",
    "\n",
    "stacked_ae = Sequential([stacked_encoder,stacked_decoder])\n",
    "model = stacked_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:45.240697Z",
     "iopub.status.busy": "2022-11-14T08:03:45.240331Z",
     "iopub.status.idle": "2022-11-14T08:03:46.287652Z",
     "shell.execute_reply": "2022-11-14T08:03:46.286333Z",
     "shell.execute_reply.started": "2022-11-14T08:03:45.240661Z"
    },
    "papermill": {
     "duration": 1.274399,
     "end_time": "2022-11-03T09:02:14.231566",
     "exception": false,
     "start_time": "2022-11-03T09:02:12.957167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='stacked_autoencoder.png', show_shapes=True)\n",
    "from IPython.display import Image\n",
    "Image(\"stacked_autoencoder.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1  style='color:#0096FF; background:#FFF ' class=\"list-group-item list-group-item-action active\">Convolutional Autoencoder</h1><a id = \"5.5\" ></a>\n",
    "\n",
    "While dealing with images, CNN's are far better suited than dense networks to work with images. So we need to build a **Convolutional autoencoder** perfectly works as an autoencoder for images. \n",
    "\n",
    "* The Convolutional encoder is a regular CNN composed of Convolutional layers and pooling layers. This typically reduces the spatial dimensionality of the inputs (i.e height and width) while increasing the depth(number of feature maps)\n",
    "\n",
    "* The Convolutional decoder must do the reverse (upscale the image and reduce its depth back to original dimensions), this is transpose Convolutional layers (alternatively combining upsampling layers with convolutional layers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:46.291584Z",
     "iopub.status.busy": "2022-11-14T08:03:46.289715Z",
     "iopub.status.idle": "2022-11-14T08:03:46.448303Z",
     "shell.execute_reply": "2022-11-14T08:03:46.447241Z",
     "shell.execute_reply.started": "2022-11-14T08:03:46.291535Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_encoder = Sequential()\n",
    "conv_encoder.add(Reshape([28,28,1],input_shape=[28,28]))\n",
    "conv_encoder.add(Conv2D(16,kernel_size=3,padding='same',activation='selu'))\n",
    "conv_encoder.add(MaxPool2D(pool_size=2))\n",
    "conv_encoder.add(Conv2D(32,kernel_size=3,padding='same',activation='selu'))\n",
    "conv_encoder.add(MaxPool2D(pool_size=2))\n",
    "conv_encoder.add(Conv2D(64,kernel_size=3,padding='same',activation='selu'))\n",
    "conv_encoder.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "conv_decoder = Sequential()\n",
    "conv_decoder.add(Conv2DTranspose(32,kernel_size=3,strides=2,padding=\"valid\",activation='selu',input_shape=[3,3,64]))\n",
    "conv_decoder.add(Conv2DTranspose(16,kernel_size=3,strides=2,padding=\"same\",activation='selu'))\n",
    "conv_decoder.add(Conv2DTranspose(1,kernel_size=3,strides=2,padding=\"same\",activation='sigmoid'))\n",
    "conv_decoder.add(Reshape([28,28]))\n",
    "\n",
    "conv_ae = Sequential([conv_encoder,conv_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:46.449853Z",
     "iopub.status.busy": "2022-11-14T08:03:46.449511Z",
     "iopub.status.idle": "2022-11-14T08:03:46.572237Z",
     "shell.execute_reply": "2022-11-14T08:03:46.571206Z",
     "shell.execute_reply.started": "2022-11-14T08:03:46.449816Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='Conv_autoencoder.png', show_shapes=True)\n",
    "from IPython.display import Image\n",
    "Image(\"Conv_autoencoder.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:46.579637Z",
     "iopub.status.busy": "2022-11-14T08:03:46.578676Z",
     "iopub.status.idle": "2022-11-14T08:03:46.584375Z",
     "shell.execute_reply": "2022-11-14T08:03:46.583121Z",
     "shell.execute_reply.started": "2022-11-14T08:03:46.579594Z"
    },
    "papermill": {
     "duration": 0.031562,
     "end_time": "2022-11-03T09:02:14.854152",
     "exception": false,
     "start_time": "2022-11-03T09:02:14.82259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Convolutional AutoEncoder model on Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:03:46.586259Z",
     "iopub.status.busy": "2022-11-14T08:03:46.585912Z",
     "iopub.status.idle": "2022-11-14T08:06:30.610253Z",
     "shell.execute_reply": "2022-11-14T08:06:30.609322Z",
     "shell.execute_reply.started": "2022-11-14T08:03:46.586224Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_ae.compile(optimizer = SGD(lr=1.5),loss = 'binary_crossentropy')\n",
    "conv_ae_fit = conv_ae.fit(x=x_train_fashion,y=x_train_fashion, epochs=epochs,validation_data=(x_val_fashion,x_val_fashion) ,verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Stacked Autoencoder model on Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:06:30.612415Z",
     "iopub.status.busy": "2022-11-14T08:06:30.611799Z",
     "iopub.status.idle": "2022-11-14T08:07:56.447537Z",
     "shell.execute_reply": "2022-11-14T08:07:56.446587Z",
     "shell.execute_reply.started": "2022-11-14T08:06:30.612375Z"
    },
    "papermill": {
     "duration": 820.915796,
     "end_time": "2022-11-03T09:15:55.792826",
     "exception": false,
     "start_time": "2022-11-03T09:02:14.87703",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = SGD(lr=1.5),loss = 'binary_crossentropy' )\n",
    "model_fit = model.fit(x=x_train_fashion,y=x_train_fashion, epochs=epochs,validation_data=(x_val_fashion,x_val_fashion) ,verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Stacked Autoencoder model on Digits MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:07:56.449308Z",
     "iopub.status.busy": "2022-11-14T08:07:56.448927Z",
     "iopub.status.idle": "2022-11-14T08:08:58.016807Z",
     "shell.execute_reply": "2022-11-14T08:08:58.015922Z",
     "shell.execute_reply.started": "2022-11-14T08:07:56.449243Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked_ae.compile(optimizer = SGD(lr=1.5),loss = 'binary_crossentropy' )\n",
    "stacked_ae_fit = stacked_ae.fit(x=x_train,y=x_train, epochs=epochs,validation_data=(x_val,x_val) ,verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.383589,
     "end_time": "2022-11-03T09:15:56.510749",
     "exception": false,
     "start_time": "2022-11-03T09:15:56.12716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1  style='color:white; background:#0096FF ; border:0;text-align: center' class=\"list-group-item list-group-item-action active\">SAVE MODEL</h1><a id = \"6.2\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-14T08:08:58.018824Z",
     "iopub.status.busy": "2022-11-14T08:08:58.018469Z",
     "iopub.status.idle": "2022-11-14T08:09:03.538401Z",
     "shell.execute_reply": "2022-11-14T08:09:03.537376Z",
     "shell.execute_reply.started": "2022-11-14T08:08:58.018789Z"
    },
    "papermill": {
     "duration": 6.423316,
     "end_time": "2022-11-03T09:16:03.268647",
     "exception": false,
     "start_time": "2022-11-03T09:15:56.845331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "conv_ae.save('saved_model/conv_ae.json')\n",
    "model.save('saved_model/stacked_autoencoder_fashion_mnist.json')\n",
    "stacked_ae.save('saved_model/stacked_autoencoder_digit_mnist.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.342836,
     "end_time": "2022-11-03T09:16:08.166791",
     "exception": false,
     "start_time": "2022-11-03T09:16:07.823955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<h1  style='color:white; background:#0096FF ; border:0;text-align: center' class=\"list-group-item list-group-item-action active\">6. PLOT & EVALUATION</h1><a id = \"8\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit MNIST compression using Stacked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:09:03.547073Z",
     "iopub.status.busy": "2022-11-14T08:09:03.544119Z",
     "iopub.status.idle": "2022-11-14T08:09:04.035306Z",
     "shell.execute_reply": "2022-11-14T08:09:04.034335Z",
     "shell.execute_reply.started": "2022-11-14T08:09:03.547034Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_compress = stacked_ae.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit MNIST compression using Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:09:04.046456Z",
     "iopub.status.busy": "2022-11-14T08:09:04.039881Z",
     "iopub.status.idle": "2022-11-14T08:09:04.552445Z",
     "shell.execute_reply": "2022-11-14T08:09:04.551244Z",
     "shell.execute_reply.started": "2022-11-14T08:09:04.046425Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_convae_compress = conv_ae.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the uncompressed and compressed MNIST Digit images together using Stacked Autoencoder and Convolutional Autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:09:04.556972Z",
     "iopub.status.busy": "2022-11-14T08:09:04.556034Z",
     "iopub.status.idle": "2022-11-14T08:09:07.384294Z",
     "shell.execute_reply": "2022-11-14T08:09:07.383337Z",
     "shell.execute_reply.started": "2022-11-14T08:09:04.556932Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(7,3,figsize=(20,30))\n",
    "axs[0][0].set_title('Original image')\n",
    "axs[0][1].set_title('Stacked Autoencoder compressed image')\n",
    "axs[0][2].set_title('Convolutional Autoencoder image compression')\n",
    "for i in range(0, 7):\n",
    "    axs[i][0].imshow(x_test[i], cmap=plt.get_cmap('gray'))\n",
    "    axs[i][1].imshow(x_test_compress[i], cmap=plt.get_cmap('gray'))\n",
    "    axs[i][2].imshow(x_test_convae_compress[i], cmap=plt.get_cmap('gray'))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST compression using Stacker Autoencoder and Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:09:07.386961Z",
     "iopub.status.busy": "2022-11-14T08:09:07.385345Z",
     "iopub.status.idle": "2022-11-14T08:09:08.000524Z",
     "shell.execute_reply": "2022-11-14T08:09:07.999436Z",
     "shell.execute_reply.started": "2022-11-14T08:09:07.386931Z"
    },
    "papermill": {
     "duration": 1.153574,
     "end_time": "2022-11-03T09:16:12.075307",
     "exception": false,
     "start_time": "2022-11-03T09:16:10.921733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test_compress = model.predict(x_test_fashion)\n",
    "fashion_compress = conv_ae.predict(x_test_fashion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the uncompressed and compressed Fashion MNIST images together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T08:09:08.002459Z",
     "iopub.status.busy": "2022-11-14T08:09:08.002087Z",
     "iopub.status.idle": "2022-11-14T08:09:10.386522Z",
     "shell.execute_reply": "2022-11-14T08:09:10.385431Z",
     "shell.execute_reply.started": "2022-11-14T08:09:08.002419Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(7,3,figsize=(20,30))\n",
    "axs[0][0].set_title('Original image')\n",
    "axs[0][1].set_title('Stacked Autoencoder compressed image')\n",
    "axs[0][2].set_title('Convolutional Autoencoder image compression')\n",
    "for i in range(0, 7):\n",
    "    axs[i][0].imshow(x_test_fashion[i], cmap=plt.get_cmap('gray'))\n",
    "    axs[i][1].imshow(x_test_compress[i], cmap=plt.get_cmap('gray'))\n",
    "    axs[i][2].imshow(fashion_compress[i], cmap=plt.get_cmap('gray'))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "      The Convolutional Autoencoder is better than Stacked Autoencoder when model is applied on compressing and decompressing Image datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.36194,
     "end_time": "2022-11-03T09:16:21.159982",
     "exception": false,
     "start_time": "2022-11-03T09:16:20.798042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### If you like my work, please do upvote. Thanks - `@tejasurya`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
